{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>purpose</th>\n",
       "      <th>yr_credit</th>\n",
       "      <th>dti</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RENT</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.65</td>\n",
       "      <td>9.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RENT</td>\n",
       "      <td>car</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RENT</td>\n",
       "      <td>small_business</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.72</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RENT</td>\n",
       "      <td>other</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RENT</td>\n",
       "      <td>other</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.94</td>\n",
       "      <td>38.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  home_ownership         purpose  yr_credit    dti  total_acc addr_state  \\\n",
       "0           RENT     credit_card       29.0  27.65        9.0         AZ   \n",
       "1           RENT             car       15.0   1.00        4.0         GA   \n",
       "2           RENT  small_business       13.0   8.72       10.0         IL   \n",
       "3           RENT           other       18.0  20.00       37.0         CA   \n",
       "4           RENT           other       18.0  17.94       38.0         OR   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89549, 7)\n"
     ]
    }
   ],
   "source": [
    "# Read off data\n",
    "lend = pd.read_csv('data/lending_ml.csv')\n",
    "display(lend.head())\n",
    "print(lend.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a classification problem. \n",
    "\n",
    "The features being selected from inference statistic are \n",
    "- homeownership\n",
    "- loan purpose\n",
    "- years of credit\n",
    "- debt to income ratio (DTI),\n",
    "- total credit lines\n",
    "- applicant's State\n",
    "\n",
    "For the first phrase modeling, we will focus on the numeric variables, which are years of credit, DTI, and total credit lines. Remaining variable will be evaluated in the next phrase for model improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create features and target numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89549, 3)\n",
      "(89549,)\n"
     ]
    }
   ],
   "source": [
    "features = lend[['dti', 'yr_credit', 'total_acc']].values\n",
    "target = lend.target.values\n",
    "\n",
    "# check shape of the features and target sets\n",
    "print(features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train and test set for all models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67161, 3)\n",
      "(22388, 3)\n",
      "(67161,)\n",
      "(22388,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features, target, test_size = .25, random_state=5)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "Assume targets to be all 1s or 0s. We use F1 score for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[    0  3431]\n",
      " [    0 18957]]\n"
     ]
    }
   ],
   "source": [
    "base_f1 = f1_score(y_val, np.ones(len(y_val)))\n",
    "base_misclassify = 1 - precision_score(y_val, np.ones(len(y_val)))\n",
    "print('Confusion Matrix \\n {}'.format(confusion_matrix(y_val, np.ones(len(y_val)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model achieves F1 score of 0.917 with misclassification rate of 0.15\n"
     ]
    }
   ],
   "source": [
    "print('Baseline Model achieves F1 score of {:.3f} with misclassification rate of {:.2f}'.format(base_f1, base_misclassify))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to **maximize F1 score** by minimal misclassification rates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Cross Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score(clf, x, y, score_func=f1_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Logistic Regression\n",
    "\n",
    "**Base Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=33)\n",
    "\n",
    "lf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lf = lf.predict(X_val)\n",
    "lf_f1_base = f1_score(y_val, y_pred_lf)\n",
    "lf_misclassify_base = 1- accuracy_score(y_val, y_pred_lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[ 1815  1616]\n",
      " [ 8588 10369]]\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.53      0.26      3431\n",
      "           1       0.87      0.55      0.67     18957\n",
      "\n",
      "   micro avg       0.54      0.54      0.54     22388\n",
      "   macro avg       0.52      0.54      0.47     22388\n",
      "weighted avg       0.76      0.54      0.61     22388\n",
      "\n",
      "Logistics Regression Base Model achieves F1 score of 0.670 with misclassification rate of 0.46\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix \\n {}'.format(confusion_matrix(y_val, y_pred_lf)))\n",
    "print('Classification report \\n {}'.format(classification_report(y_val, y_pred_lf)))\n",
    "print('Logistics Regression Base Model achieves F1 score of {:.3f} with misclassification rate of {:.2f}'.format(lf_f1_base, lf_misclassify_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation f1 score for Logistic Regression Base Model: 0.668\n"
     ]
    }
   ],
   "source": [
    "score_lf = cv_score(lf, X_train, y_train)\n",
    "print('Cross validation f1 score for Logistic Regression Base Model: {:.4}'. format(score_lf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: Comparing to baseline model, Logistic Regression help on limiting Type 1 error (approved loan requests that will default), it also lead to miss opportunity of introducing Type 2 error (rejected loan requests that would paid off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tunning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter: {'C': 10}\n",
      "Confusion Matrix:\n",
      " [[ 1815  1616]\n",
      " [ 8585 10372]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.53      0.26      3431\n",
      "           1       0.87      0.55      0.67     18957\n",
      "\n",
      "   micro avg       0.54      0.54      0.54     22388\n",
      "   macro avg       0.52      0.54      0.47     22388\n",
      "weighted avg       0.76      0.54      0.61     22388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Grid search to look for the best C\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "gridsearch_lf = GridSearchCV(estimator=lf, param_grid={'C': Cs}, cv=5, scoring='f1')\n",
    "gridsearch_lf.fit(X_train, y_train)\n",
    "y_pred_lf_c = gridsearch_lf.best_estimator_.predict(X_val)\n",
    "print('best parameter: {}'.format(gridsearch_lf.best_params_))\n",
    "print('Confusion Matrix:\\n {}'.format(confusion_matrix(y_val, y_pred_lf_c)))\n",
    "print('Classification Report:\\n {}'.format(classification_report(y_val, y_pred_lf_c)))\n",
    "lf_f1_tune = f1_score(y_val, y_pred_lf_c)\n",
    "lf_misclassify_tune = 1- accuracy_score(y_val, y_pred_lf_c)\n",
    "score_lf_tune = gridsearch_lf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistics Regression Tuned Model achieves F1 score of 0.670 with misclassification rate of 0.46\n",
      "Cross validation f1 score for Logistic Regression Tuned Model: 0.668\n"
     ]
    }
   ],
   "source": [
    "print('Logistics Regression Tuned Model achieves F1 score of {:.3f} with misclassification rate of {:.2f}'.format(lf_f1_tune, lf_misclassify_tune))\n",
    "print('Cross validation f1 score for Logistic Regression Tuned Model: {:.4}'. format(score_lf_tune))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tunning does not improve model performance. We will still set C =10 to enable more consistent model performance when it is being applied to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Random Forest\n",
    "\n",
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 trees\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=33, class_weight='balanced_subsample')\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_val)\n",
    "rf_f1_base = f1_score(y_val, y_pred_rf)\n",
    "rf_misclassify_base = 1- accuracy_score(y_val, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[  354  3077]\n",
      " [ 1584 17373]]\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.10      0.13      3431\n",
      "           1       0.85      0.92      0.88     18957\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     22388\n",
      "   macro avg       0.52      0.51      0.51     22388\n",
      "weighted avg       0.75      0.79      0.77     22388\n",
      "\n",
      "Random Forest Base Model achieves F1 score of 0.882 with misclassification rate of 0.21\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix: \\n {}'.format(confusion_matrix(y_val,y_pred_rf)))\n",
    "print('Classification report \\n {}'.format(classification_report(y_val, y_pred_rf)))\n",
    "print('Random Forest Base Model achieves F1 score of {:.3f} with misclassification rate of {:.2f}'.format(rf_f1_base, rf_misclassify_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation f1 score for Random Forest Base Model: 0.8803\n"
     ]
    }
   ],
   "source": [
    "score_rf = cv_score(rf, X_train, y_train)\n",
    "print('Cross validation f1 score for Random Forest Base Model: {:.4}'.format(score_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: Random Forest F1 score with cross validation performs better than Logistic Regression, though below baseline model. The model start disqualifying bad loans, but also disqualifying good loans.\n",
    "\n",
    "We will tune the model to seek for performance improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tunning model\n",
    "\n",
    "Due to computational costs, we pick two more popular hyper-parameters (n_estimators and max_features) for tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [10, 100, 500, 1000],\n",
    "    'max_features' : ['auto', 'sqrt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_1 = RandomForestClassifier(random_state=33, class_weight='balanced_subsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_rf = GridSearchCV(estimator=rf_1, param_grid=param_grid, cv= 5, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators='warn', n_jobs=None, oob_score=False,\n",
       "            random_state=33, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=3,\n",
       "       param_grid={'n_estimators': [10, 100, 500, 1000], 'max_features': ['auto', 'sqrt']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'max_features': 'auto', 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: {}'.format(gridsearch_rf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting using the model with the best estimators\n",
    "y_pred_rf_tune = gridsearch_rf.best_estimator_.predict(X_val)\n",
    "rf_f1_tune = f1_score(y_val, y_pred_rf_tune)\n",
    "rf_misclassify_tune = 1 - accuracy_score(y_val, y_pred_rf_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[  354  3077]\n",
      " [ 1584 17373]]\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.10      0.13      3431\n",
      "           1       0.85      0.92      0.88     18957\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     22388\n",
      "   macro avg       0.52      0.51      0.51     22388\n",
      "weighted avg       0.75      0.79      0.77     22388\n",
      "\n",
      "Random Forest Tuned Model achieves F1 score of 0.882 with misclassification rate of 0.21\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix: \\n {}'.format(confusion_matrix(y_val,y_pred_rf)))\n",
    "print('Classification report \\n {}'.format(classification_report(y_val, y_pred_rf)))\n",
    "print('Random Forest Tuned Model achieves F1 score of {:.3f} with misclassification rate of {:.2f}'.format(rf_f1_tune, rf_misclassify_tune))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not see improvement in F1 score. We will keep the base Random Forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Summary\n",
    "\n",
    "|Model | F1 score (cross validated)| misclassification rate |\n",
    "|----- | -------|------|\n",
    "|Baseline | 0.917| .15 |\n",
    "|Logistic Regression | 0.670 | .46 |\n",
    "|Random Forest | 0.883 | .21 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Recommendation\n",
    "\n",
    "While neither model has F1 score higher than baseline, Random Forest has a high enough f1 score that we can keep improving on. We recommend Random Forest as the winning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_amnt  funded_amnt  funded_amnt_inv        term int_rate  installment  \\\n",
      "0    10000.0      10000.0          10000.0   36 months    9.67%       321.13   \n",
      "1    20800.0      20800.0          20800.0   36 months   13.53%       706.16   \n",
      "2     8000.0       8000.0           8000.0   36 months   10.99%       261.88   \n",
      "3    28000.0      28000.0          28000.0   36 months    7.62%       872.52   \n",
      "4    11500.0      11500.0          11500.0   60 months   22.90%       323.54   \n",
      "\n",
      "  grade sub_grade           emp_title emp_length  ... total_bal_ex_mort  \\\n",
      "0     B        B1    Registered Nurse    7 years  ...           39143.0   \n",
      "1     B        B5  Operations Manager  10+ years  ...           23473.0   \n",
      "2     B        B2       PARTS MANAGER    2 years  ...           15949.0   \n",
      "3     A        A3  Area Sales Manager    5 years  ...          199739.0   \n",
      "4     E        E4           Secretary    4 years  ...           24724.0   \n",
      "\n",
      "   total_bc_limit total_il_high_credit_limit hardship_flag  \\\n",
      "0          9200.0                    36186.0             N   \n",
      "1         15000.0                        0.0             N   \n",
      "2          8200.0                    12426.0             N   \n",
      "3         42200.0                   196686.0             N   \n",
      "4          9000.0                    16791.0             N   \n",
      "\n",
      "  debt_settlement_flag loan_start_d yr_emp yr_credit revol_util_dec target  \n",
      "0                    N   2013-12-01    7.0      25.0          0.444      1  \n",
      "1                    N   2013-12-01   10.0      16.0          0.545      1  \n",
      "2                    N   2013-12-01    2.0      23.0          0.346      0  \n",
      "3                    N   2013-12-01    5.0      20.0          0.546      1  \n",
      "4                    N   2013-12-01    4.0      15.0          0.709      1  \n",
      "\n",
      "[5 rows x 92 columns]\n",
      "(134814, 92)\n"
     ]
    }
   ],
   "source": [
    "# importing error test data (2013)\n",
    "test_data = pd.read_csv('data\\lending_test.csv')\n",
    "display(test_data.head())\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the needed features and target from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134814, 3)\n",
      "(134814,)\n"
     ]
    }
   ],
   "source": [
    "features_test = test_data[['yr_credit', 'dti', 'total_acc']].values\n",
    "target_test = test_data.target.values\n",
    "\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Random Forest Base Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = rf.predict(features_test)\n",
    "f1_test = f1_score(target_test, test_pred)\n",
    "misclassify_test = 1 - accuracy_score(target_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[  1500  19527]\n",
      " [  8625 105162]]\n",
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.07      0.10     21027\n",
      "           1       0.84      0.92      0.88    113787\n",
      "\n",
      "   micro avg       0.79      0.79      0.79    134814\n",
      "   macro avg       0.50      0.50      0.49    134814\n",
      "weighted avg       0.73      0.79      0.76    134814\n",
      "\n",
      "F1 score with test data is 0.8815 with misclassification rate of 0.209\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix \\n {}'.format(confusion_matrix(target_test, y_pred_test)))\n",
    "print('Classification Report \\n {}'.format(classification_report(target_test, y_pred_test)))\n",
    "print('F1 score with test data is {:.4f} with misclassification rate of {:.3f}'.format(f1_test, misclassify_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score is similar to the train score. The model performs consistently when applying to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "1. Random Forest has balanced performance (high F1 score). \n",
    "2. The model enables Lending Club to filter out some bad loan requests which would reduce profit loss driven by loan defaults. However, the model introduces type 2 error which represents loss revenue by rejecting loan requests that would paid off. Lending Club would need to weigh between the two trade offs and define the threshold tolerance on the potential misclassification. \n",
    "2. From Data Exploratory Analysis, we identified that loan purpose is likely to impact loan paid off rate. A lot of applicants work in the military."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side Notes**: Based on the data samples, we found out average default rate for Lending Club's loan is ~15%, which is higher than residential and consumer loans default rates within the United States among similar period based on [Federal Reserve Broad](https://www.federalreserve.gov/releases/chargeoff/delallsa.htm) There are motivations to continue fine-tuning the model to help Lending Club to lower the loan default rate to be more in line with the industry standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Improvements\n",
    "\n",
    "- Introduce categorical features into the model to seek further improvement on F1 score.\n",
    "- Cross-validation should be done in the form of Time Series Nested Cross-Validation to avoid contamination of time component on predicting results.\n",
    "- Access 1-2 more classification models to have a broader measurement for model performance. I would consider Extreme Gradient Boosting and Support Vector Machines, for example.\n",
    "- Features engineering which includes clustering to capture potential patterns that were not captured by looking at one feature alone.\n",
    "- Run correlation test across features to access potential collinearity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
